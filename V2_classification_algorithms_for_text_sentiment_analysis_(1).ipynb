{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the datasets\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n"
      ],
      "metadata": {
        "id": "oKT8ZstoYUXF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Preprocess the data (assuming basic preprocessing)\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation and numbers\n",
        "    text = ''.join([char for char in text if char.isalpha() or char.isspace()])\n",
        "    return text\n",
        "\n",
        "train_data['processed_text'] = train_data['text'].apply(preprocess_text)\n",
        "test_data['processed_text'] = test_data['text'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "cSnXzC7GZZpB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Feature extraction using various methods (BoW, TF-IDF, embeddings, etc.)\n",
        "# Option 1: TF-IDF vectors\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(train_data['processed_text'])\n",
        "X_test_tfidf = vectorizer.transform(test_data['processed_text'])\n",
        "\n",
        "# Uncomment for Option 2: Word embeddings\n",
        "# X_train = # Extract word embeddings for train_data\n",
        "# X_test = # Extract word embeddings for test_data\n",
        "\n",
        "y_train = train_data['label']"
      ],
      "metadata": {
        "id": "DyJ6vCK9ZhhF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Split the data into training and validation sets\n",
        "X_train_tfidf, X_val_tfidf, y_train, y_val = train_test_split(\n",
        "    X_train_tfidf, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "CxHvZfYVZeeX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train classifiers (Logistic Regression, Naive Bayes, SVM, etc.)\n",
        "# Option 1: Logistic Regression\n",
        "classifier_lr_tfidf = LogisticRegression(max_iter=50)\n",
        "classifier_lr_tfidf.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr_tfidf = classifier_lr_tfidf.predict(X_val_tfidf)\n",
        "accuracy_lr_tfidf = accuracy_score(y_val, y_pred_lr_tfidf)\n",
        "print('Logistic Regression (TF-IDF) Accuracy:', accuracy_lr_tfidf)\n",
        "\n",
        "# Option 2: Naive Bayes Classifier\n",
        "classifier_nb_tfidf = MultinomialNB()\n",
        "classifier_nb_tfidf.fit(X_train_tfidf, y_train)\n",
        "y_pred_nb_tfidf = classifier_nb_tfidf.predict(X_val_tfidf)\n",
        "accuracy_nb_tfidf = accuracy_score(y_val, y_pred_nb_tfidf)\n",
        "print('Naive Bayes (TF-IDF) Accuracy:', accuracy_nb_tfidf)\n",
        "\n",
        "# Option 3: SVM Classifier\n",
        "classifier_svm_tfidf = SVC(max_iter=50)\n",
        "classifier_svm_tfidf.fit(X_train_tfidf, y_train)\n",
        "y_pred_svm_tfidf = classifier_svm_tfidf.predict(X_val_tfidf)\n",
        "accuracy_svm_tfidf = accuracy_score(y_val, y_pred_svm_tfidf)\n",
        "print('SVM (TF-IDF) Accuracy:', accuracy_svm_tfidf)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLxH84DwZrEN",
        "outputId": "da05a586-4eef-46e6-aaa4-b2d5e4ae748d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (TF-IDF) Accuracy: 0.6210826210826211\n",
            "Naive Bayes (TF-IDF) Accuracy: 0.5842830009496676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM (TF-IDF) Accuracy: 0.42663817663817666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Make predictions on the test set\n",
        "test_predictions_lr_tfidf = classifier_lr_tfidf.predict(X_test_tfidf)\n",
        "test_predictions_nb_tfidf = classifier_nb_tfidf.predict(X_test_tfidf)\n",
        "test_predictions_svm_tfidf = classifier_svm_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "# Additional Comments:\n",
        "# We chose TF-IDF as a feature because it captures the importance of words in each document\n",
        "# relative to the entire corpus. TF-IDF considers both the term frequency (TF) and inverse\n",
        "# document frequency (IDF), allowing us to identify the most distinctive words for each document.\n",
        "# In the context of sentiment analysis, TF-IDF can help identify words or phrases that are\n",
        "# indicative of positive or negative sentiment. This feature can be valuable in capturing the\n",
        "# sentiment expressed in the reviews.\n",
        "#\n",
        "# Combining TF-IDF vectors and topic modeling can be achieved through different approaches. One\n",
        "# possible approach is using a voting system, where each model's prediction (e.g., TF-IDF-based\n",
        "# classifier and topic modeling-based classifier) is considered as a vote. The final prediction\n",
        "# can be determined based on majority voting, equal votes, or a weighted voting system, where more\n",
        "# trustworthy models are given more weight.\n",
        "#\n",
        "# Another approach is stacking models, which involves using the predictions from the initial models\n",
        "# (e.g., TF-IDF-based classifier and topic modeling-based classifier) as input features to a\n",
        "# second-level model, also known as a \"meta-learner.\" The meta-learner can be trained to make the\n",
        "# final prediction based on the outputs of the initial models. This approach allows for the\n",
        "# combination of different features and can potentially improve the overall predictive performance\n",
        "# by learning from the strengths of each model."
      ],
      "metadata": {
        "id": "mI-zDrO2Z03v"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}